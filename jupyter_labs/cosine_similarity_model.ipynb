{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Content-Based recommendation system based on Cosine Similarity method\n","\n","This system will generate a list of books that the user might be interested in by giving a book ISBN.\n","\n","The recommendations will be generated by vectorizing (Word Frequency or TF-IDF) the book's features (Genres, Authors ...), and computing the cosine similarity between vectors."]},{"cell_type":"markdown","metadata":{},"source":["## 01 - Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"ti3dtP1gFIkS","colab_type":"code","outputId":"a9bcf242-5a43-4de7-a5dc-8bd50ed699c5","executionInfo":{"status":"ok","timestamp":1588777768134,"user_tz":0,"elapsed":652,"user":{"displayName":"mehdi abidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgidNwwfK1PDiKFSAZDe_naoPooXLQ88iQnjmWZ=s64","userId":"18178744226545703489"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Import libraries\n","import numpy as np\n","import pandas as pd\n","\n","# CountVectorizer vectorize a document by generating his words frequency\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# cosine_similarity to compute the difference between two vectors\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# ntlk stopwords function will help ignore non-contextuel words like (the, or, she)\n","# during document vectorizing\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download(\"stopwords\", quiet=True)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{},"source":["### About the dataset\n","\n","This dataset provides some books metadata (pages, category ..)\n","\n","Columns:\n","- isbn: Universal books identifier\n","- title: Book's tilte\n","- pages: Number of pages\n","- category: Book's category\n","- author: Book's author\n","- publisher: Book's publisher"]},{"cell_type":"code","metadata":{"id":"zJPQwS5xF5CK","colab_type":"code","outputId":"0a37761f-0228-4347-ddd5-1c7c70fb9df0","executionInfo":{"status":"ok","timestamp":1588777545748,"user_tz":0,"elapsed":8440,"user":{"displayName":"mehdi abidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgidNwwfK1PDiKFSAZDe_naoPooXLQ88iQnjmWZ=s64","userId":"18178744226545703489"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# Step 01: Read Books Data\n","df = pd.read_csv(\n","    \"dataset/books.csv\",\n","    sep=\";\",\n","    usecols=[\"isbn\", \"title\", \"publisher\", \"category\", \"author\"],\n","    dtype={\"isbn\":np.str}\n",")\n","\n","df.info(memory_usage=\"deep\")\n","df.head()"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 11622 entries, 0 to 11621\nData columns (total 5 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   isbn       11622 non-null  object\n 1   title      11622 non-null  object\n 2   category   11622 non-null  object\n 3   author     11622 non-null  object\n 4   publisher  11622 non-null  object\ndtypes: object(5)\nmemory usage: 3.9 MB\n"},{"output_type":"execute_result","data":{"text/plain":"         isbn                                              title    category  \\\n0  0782128726                      Mastering Windows 2000 Server   Computers   \n1  0782128726                      Mastering Windows 2000 Server   Computers   \n2  0789711427                         Using Microsoft Backoffice   Computers   \n3  0691097186  The Collected Dialogues Of Plato, Including Th...     Ancient   \n4  0691097186  The Collected Dialogues Of Plato, Including Th...  Philosophy   \n\n           author                   publisher  \n0  brian m. smith                   Sybex Inc  \n1     doug toombs                   Sybex Inc  \n2      don benage      Macmillan Computer Pub  \n3           plato  Princeton University Press  \n4           plato  Princeton University Press  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>title</th>\n      <th>category</th>\n      <th>author</th>\n      <th>publisher</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0782128726</td>\n      <td>Mastering Windows 2000 Server</td>\n      <td>Computers</td>\n      <td>brian m. smith</td>\n      <td>Sybex Inc</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0782128726</td>\n      <td>Mastering Windows 2000 Server</td>\n      <td>Computers</td>\n      <td>doug toombs</td>\n      <td>Sybex Inc</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0789711427</td>\n      <td>Using Microsoft Backoffice</td>\n      <td>Computers</td>\n      <td>don benage</td>\n      <td>Macmillan Computer Pub</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0691097186</td>\n      <td>The Collected Dialogues Of Plato, Including Th...</td>\n      <td>Ancient</td>\n      <td>plato</td>\n      <td>Princeton University Press</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0691097186</td>\n      <td>The Collected Dialogues Of Plato, Including Th...</td>\n      <td>Philosophy</td>\n      <td>plato</td>\n      <td>Princeton University Press</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Features considered in content filtering\n","features = [\"isbn\", \"publisher\", \"category\", \"author\"]"]},{"cell_type":"code","metadata":{"id":"dIIAmvC-i9K6","colab_type":"code","outputId":"31b38b71-ffa6-4b94-ea28-90ec49c1b861","executionInfo":{"status":"ok","timestamp":1588777617618,"user_tz":0,"elapsed":4155,"user":{"displayName":"mehdi abidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgidNwwfK1PDiKFSAZDe_naoPooXLQ88iQnjmWZ=s64","userId":"18178744226545703489"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# Join all the features in one column to build a bag of words\n","books_df = df[features].groupby(\"isbn\").agg(lambda cell_val: ' '.join(set(cell_val)))\n","books_df[\"features\"] = books_df[features[1:]].apply(lambda row: \" \".join(row.fillna(\"\")), axis=1)\n","\n","# Delete unecessary features\n","books_df.drop(features[1:], axis=1, inplace=True)\n","\n","books_df.info(memory_usage=\"deep\")\n","books_df.head()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 9399 entries, 0002251760 to 950491036X\nData columns (total 1 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   features  9399 non-null   object\ndtypes: object(1)\nmemory usage: 1.5 MB\n"},{"output_type":"execute_result","data":{"text/plain":"                                                     features\nisbn                                                         \n0002251760                 Harpercollins Fiction nick bantock\n000648302X  Harpercollins (Uk) End Of The World matthew th...\n0006543545  Flamingo Booksellers And Bookselling penelope ...\n0007106572         Harpercollins Domestic Fiction sue welfare\n0007154615                    Perennial Fiction carol shields","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n    </tr>\n    <tr>\n      <th>isbn</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0002251760</th>\n      <td>Harpercollins Fiction nick bantock</td>\n    </tr>\n    <tr>\n      <th>000648302X</th>\n      <td>Harpercollins (Uk) End Of The World matthew th...</td>\n    </tr>\n    <tr>\n      <th>0006543545</th>\n      <td>Flamingo Booksellers And Bookselling penelope ...</td>\n    </tr>\n    <tr>\n      <th>0007106572</th>\n      <td>Harpercollins Domestic Fiction sue welfare</td>\n    </tr>\n    <tr>\n      <th>0007154615</th>\n      <td>Perennial Fiction carol shields</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{},"source":["## 02 - Building the recommendation system"]},{"cell_type":"markdown","metadata":{},"source":["In order to build our recommender, we have to vectorize the book features (bag of words), \n","after that we can calculate the similarity score of those vectors with the Cosine Similarity method.\n","\n","there are differenct techniques to vectorize your documents, like term frequency or TF-IDF technique.\n","\n","for this Lab, we are going to use term frequency technique with the CountVectorizer function in ScLearn library."]},{"cell_type":"code","metadata":{"id":"XGBDts5MD5OV","colab_type":"code","colab":{}},"source":["# Define words to ignore during document vectorizing, stop words such as 'the', 'a', 'et', \"she ...\"\n","stopwords_list = stopwords.words('english') + stopwords.words('french')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"81TTqZRxFS2B","colab_type":"code","outputId":"80363b10-214d-4421-b593-7c6b30c9442f","executionInfo":{"status":"ok","timestamp":1588777779123,"user_tz":0,"elapsed":523,"user":{"displayName":"mehdi abidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgidNwwfK1PDiKFSAZDe_naoPooXLQ88iQnjmWZ=s64","userId":"18178744226545703489"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Instanciate a count Vectorizer Object\n","count = CountVectorizer(stop_words=stopwords_list)\n","\n","\n","# Construct the sparse Count matrix by fitting and transforming the bag of words\n","count_matrix = count.fit_transform(books_df['features'])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"OzXzel2pKR0q","colab_type":"code","colab":{}},"source":["# Compute the cosine similarity matrix\n","cosine_matrix = cosine_similarity(count_matrix, count_matrix)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["## 03 - Books Recommendation\n","\n","After generating the cosine similarity matrix, we can retrieve book's recommendation list by getting his position index in the main dataframe \"books_df\".\n","\n","But we can also build a dataframe upon the cosine similarity matrix to help us retreive a book recommendation list by its ISBN."]},{"cell_type":"code","metadata":{"id":"1OYl9ab0RSVZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"outputId":"e75eeee7-980c-4c5a-a221-078e68ed6f06","executionInfo":{"status":"ok","timestamp":1588777831343,"user_tz":0,"elapsed":507,"user":{"displayName":"mehdi abidar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgidNwwfK1PDiKFSAZDe_naoPooXLQ88iQnjmWZ=s64","userId":"18178744226545703489"}}},"source":["# Convert the cosine similarity matrix to a dataframe\n","# In order to facilitate books retrieving\n","cosine_sim_df = pd.DataFrame(cosine_matrix, columns=books_df.index, index=books_df.index)\n","cosine_sim_df.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":"isbn        0002251760  000648302X  0006543545  0007106572  0007154615  \\\nisbn                                                                     \n0002251760    1.000000    0.204124         0.0    0.447214    0.250000   \n000648302X    0.204124    1.000000         0.0    0.182574    0.000000   \n0006543545    0.000000    0.000000         1.0    0.000000    0.000000   \n0007106572    0.447214    0.182574         0.0    1.000000    0.223607   \n0007154615    0.250000    0.000000         0.0    0.223607    1.000000   \n\nisbn        000716226X  0020198906  0020360754  0020418809  0020768702  ...  \\\nisbn                                                                    ...   \n0002251760    0.223607         0.0    0.250000    0.000000    0.188982  ...   \n000648302X    0.000000         0.0    0.000000    0.000000    0.000000  ...   \n0006543545    0.000000         0.0    0.000000    0.000000    0.000000  ...   \n0007106572    0.200000         0.0    0.223607    0.000000    0.169031  ...   \n0007154615    0.223607         0.0    0.250000    0.204124    0.188982  ...   \n\nisbn        8807812576  8807813025  8817125539  8838918600  8845247414  \\\nisbn                                                                     \n0002251760    0.176777    0.223607    0.204124    0.250000    0.204124   \n000648302X    0.000000    0.000000    0.000000    0.000000    0.000000   \n0006543545    0.000000    0.000000    0.000000    0.000000    0.000000   \n0007106572    0.158114    0.200000    0.182574    0.223607    0.182574   \n0007154615    0.176777    0.223607    0.204124    0.250000    0.204124   \n\nisbn        8845407039  8878188212  9004121390  902470068X  950491036X  \nisbn                                                                    \n0002251760    0.204124    0.188982         0.0         0.0    0.223607  \n000648302X    0.000000    0.000000         0.0         0.0    0.000000  \n0006543545    0.000000    0.000000         0.0         0.0    0.000000  \n0007106572    0.182574    0.169031         0.0         0.0    0.200000  \n0007154615    0.204124    0.188982         0.0         0.0    0.223607  \n\n[5 rows x 9399 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>isbn</th>\n      <th>0002251760</th>\n      <th>000648302X</th>\n      <th>0006543545</th>\n      <th>0007106572</th>\n      <th>0007154615</th>\n      <th>000716226X</th>\n      <th>0020198906</th>\n      <th>0020360754</th>\n      <th>0020418809</th>\n      <th>0020768702</th>\n      <th>...</th>\n      <th>8807812576</th>\n      <th>8807813025</th>\n      <th>8817125539</th>\n      <th>8838918600</th>\n      <th>8845247414</th>\n      <th>8845407039</th>\n      <th>8878188212</th>\n      <th>9004121390</th>\n      <th>902470068X</th>\n      <th>950491036X</th>\n    </tr>\n    <tr>\n      <th>isbn</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0002251760</th>\n      <td>1.000000</td>\n      <td>0.204124</td>\n      <td>0.0</td>\n      <td>0.447214</td>\n      <td>0.250000</td>\n      <td>0.223607</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.000000</td>\n      <td>0.188982</td>\n      <td>...</td>\n      <td>0.176777</td>\n      <td>0.223607</td>\n      <td>0.204124</td>\n      <td>0.250000</td>\n      <td>0.204124</td>\n      <td>0.204124</td>\n      <td>0.188982</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.223607</td>\n    </tr>\n    <tr>\n      <th>000648302X</th>\n      <td>0.204124</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.182574</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>0006543545</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>0007106572</th>\n      <td>0.447214</td>\n      <td>0.182574</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.223607</td>\n      <td>0.200000</td>\n      <td>0.0</td>\n      <td>0.223607</td>\n      <td>0.000000</td>\n      <td>0.169031</td>\n      <td>...</td>\n      <td>0.158114</td>\n      <td>0.200000</td>\n      <td>0.182574</td>\n      <td>0.223607</td>\n      <td>0.182574</td>\n      <td>0.182574</td>\n      <td>0.169031</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.200000</td>\n    </tr>\n    <tr>\n      <th>0007154615</th>\n      <td>0.250000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.223607</td>\n      <td>1.000000</td>\n      <td>0.223607</td>\n      <td>0.0</td>\n      <td>0.250000</td>\n      <td>0.204124</td>\n      <td>0.188982</td>\n      <td>...</td>\n      <td>0.176777</td>\n      <td>0.223607</td>\n      <td>0.204124</td>\n      <td>0.250000</td>\n      <td>0.204124</td>\n      <td>0.204124</td>\n      <td>0.188982</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.223607</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 9399 columns</p>\n</div>"},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"isbn\n1575213168    0.676123\n1562056417    0.617213\n0789706814    0.617213\n0672306204    0.617213\n1562057154    0.617213\n1562056484    0.617213\n0672306670    0.617213\n1562055089    0.617213\n0672308002    0.617213\n0789705672    0.617213\nName: 0789711427, dtype: float64"},"metadata":{},"execution_count":17}],"source":["#  Simulate recommendation proccess\n","\n","# Random book identifier\n","book_isbn = \"0789711427\"\n","\n","# Get the book similarity score with other books\n","books_score = cosine_sim_df.loc[book_isbn]\n","\n","# Sort score and retrieve the top 10\n","# We ignore the first book, its always the same book\n","recommended_books = books_score.sort_values(ascending=False)[1:11]\n","\n","recommended_books"]},{"cell_type":"markdown","metadata":{},"source":["04 - Into production\n","Repeating those steps every time a user requests production, it will not help to scale the system.\n","\n","But we can consider the \"02 - Building the recommendation system\" section as a model training step, and instead of repeating the training for each request, we can save the cosine similarity data and interrogate this dataframe in every request.\n","\n","For the saving techniques, we can save the dataframe in memory (Redis database) or as a file in the file system as a binary file.\n","for the sake of simplicity, we will save it as parquet file (you can read this article about Pandas file benchmarking)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Saving cosine similarity datatframe\n","cosine_sim_df.to_parquet(\"books_cosine_similarity.parquet\")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"isbn\n1575213168    0.676123\n1562056417    0.617213\n0789706814    0.617213\n0672306204    0.617213\n1562057154    0.617213\n1562056484    0.617213\n0672306670    0.617213\n1562055089    0.617213\n0672308002    0.617213\n0789705672    0.617213\nName: 0789711427, dtype: float64"},"metadata":{},"execution_count":21}],"source":["#  Simulate recommendation proccess\n","\n","books_cos_df = pd.read_parquet(\"books_cosine_similarity.parquet\")\n","# Read cosine similarity dataframe file\n","# Random book identifier\n","book_isbn = \"0789711427\"\n","\n","# Get the book similarity score with other books\n","books_score = books_cos_df.loc[book_isbn]\n","\n","# Sort score and retrieve the top 10\n","# We ignore the first book, its always the same book\n","recommended_books = books_score.sort_values(ascending=False)[1:11]\n","\n","recommended_books"]}],"metadata":{"colab":{"name":"content-based recommender project 02.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1nsp9h0HyIUlwNOboRDSM4bPwFH6kFxUd","authorship_tag":"ABX9TyNDvX7cxoe4vKWY/59+Z+gw"},"kernelspec":{"name":"python38264bitef642cc30e064c809ba62cfeb209eed4","display_name":"Python 3.8.2 64-bit"}},"nbformat":4,"nbformat_minor":0}